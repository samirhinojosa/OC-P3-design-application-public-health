{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d998865-863c-4e29-9bd1-fac74abc8367",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Design an application for public health - Project 3</h1>\n",
    "<h2 align=\"center\">| Cleaning notebook |</h2>\n",
    "<h3 align=\"center\">Data Scientist course - OpenClassrooms</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c9799-07f8-4e66-9f06-0d91e4c08154",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">1. Libraries and functions</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e270f8-ca43-4dac-a9c7-3f3c988485d5",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">1.1. Libraries and functions</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ac3496-3e4a-4453-a700-309feaecbbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import gc\n",
    "import math\n",
    "from math import prod\n",
    "from collections import Counter\n",
    "import time as time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb5f545-eeca-47bc-8cff-5720bffbc3e1",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">1.2. Functions declaration</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6edd7e59-4773-41e6-8813-81e1ddea530d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_analysis(df, name_df, columns, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Method used for analyzing on the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    -----------------\n",
    "        df (pandas.DataFrame): Dataset to analyze\n",
    "        name_df (str): Dataset name\n",
    "        columns (list): Dataframe keys in list format\n",
    "        \n",
    "        *args, **kwargs:\n",
    "        -----------------\n",
    "            flag (str): Flag to show complete information about the dataset to analyse\n",
    "                        \"complete\" shows all information about the dataset\n",
    "\n",
    "    Returns:\n",
    "    -----------------\n",
    "        None. \n",
    "        Print the analysis on the Dataset. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting the variables\n",
    "    flag = kwargs.get(\"flag\", None)\n",
    "    \n",
    "    ORDERING_COMPLETE = [\n",
    "        \"name\", \"type\", \"records\", \"unique\", \"# NaN\", \"% NaN\", \"mean\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"std\"\n",
    "    ]\n",
    "    \n",
    "    # Calculating the memory usage based on dataframe.info()\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    memory_usage = buf.getvalue().split('\\n')[-2]\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"The\", name_df, \"dataset is empty. Please verify the file.\")\n",
    "    else:\n",
    "        empty_cols = [col for col in df.columns if df[col].isna().all()] # identifying empty columns\n",
    "        df_rows_duplicates = df[df.duplicated()] #identifying full duplicates rows\n",
    "        \n",
    "        # Creating a dataset based on Type object and records by columns\n",
    "        type_cols = df.dtypes.apply(lambda x: x.name).to_dict() \n",
    "        df_resume = pd.DataFrame(list(type_cols.items()), columns = [\"name\", \"type\"])\n",
    "        df_resume[\"records\"] = list(df.count())\n",
    "        df_resume[\"# NaN\"] = list(df.isnull().sum())\n",
    "        df_resume[\"% NaN\"] = list(((df.isnull().sum() / len(df.index))*100).round(2))\n",
    "        \n",
    "        print(\"\\nAnalysis of\", name_df, \"dataset\")\n",
    "        print(\"--------------------------------------------------------------------\")\n",
    "        print(\"- Dataset shape:                 \", df.shape[0], \"rows and\", df.shape[1], \"columns\")\n",
    "        print(\"- Total of NaN values:           \", df.isna().sum().sum())\n",
    "        print(\"- Percentage of NaN:             \", round((df.isna().sum().sum() / prod(df.shape)) * 100, 2), \"%\")\n",
    "        print(\"- Total of full duplicates rows: \", df_rows_duplicates.shape[0])\n",
    "        print(\"- Total of empty rows:           \", df.shape[0] - df.dropna(axis=\"rows\", how=\"all\").shape[0]) if df.dropna(axis=\"rows\", how=\"all\").shape[0] < df.shape[0] else \\\n",
    "                    print(\"- Total of empty rows:            0\")\n",
    "        print(\"- Total of empty columns:        \", len(empty_cols))\n",
    "        print(\"  + The empty column is:         \", empty_cols) if len(empty_cols) == 1 else \\\n",
    "                    print(\"  + The empty column are:         \", empty_cols) if len(empty_cols) >= 1 else None\n",
    "        print(\"- Unique indexes:                \", df.index.is_unique)\n",
    "        \n",
    "        print(\"\\n- The key(s):\", columns, \"is not present multiple times in the dataframe.\\n  It CAN be used as a primary key.\") if df.size == df.drop_duplicates(columns).size else \\\n",
    "            print(\"\\n- The key(s):\", columns, \"is present multiple times in the dataframe.\\n  It CANNOT be used as a primary key.\")\n",
    "        \n",
    "        pd.set_option(\"display.max_rows\", None) # show full of showing rows\n",
    "        pd.set_option(\"display.max_columns\", None) # show full of showing cols\n",
    "        pd.set_option(\"max_colwidth\", None) # show full width of showing cols\n",
    "        \n",
    "        if flag is None or flag != \"complete\":\n",
    "            print(\"\\n- Type object and records by columns   (\",memory_usage,\")\")\n",
    "            print(\"--------------------------------------------------------------------\")\n",
    "        elif flag == \"complete\":\n",
    "            df_resume[\"unique\"] = list(df.nunique())\n",
    "            df_desc = pd.DataFrame(df.describe().T).reset_index()\n",
    "            df_desc = df_desc.rename(columns={\"index\": \"name\"})\n",
    "            df_resume = df_resume.merge(right=df_desc[[\"name\", \"mean\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"std\"]], on=\"name\", how=\"left\")\n",
    "            df_resume = df_resume[ORDERING_COMPLETE]\n",
    "            print(\"\\n- Type object and records by columns                                                                   (\",memory_usage,\")\")\n",
    "            print(\"---------------------------------------------------------------------------------------------------------------------------------\")\n",
    "        \n",
    "        display(df_resume.sort_values(\"records\", ascending=False))\n",
    "        \n",
    "        pd.reset_option(\"display.max_rows\") # reset max of showing rows\n",
    "        pd.reset_option(\"display.max_columns\") # reset max of showing cols\n",
    "        pd.reset_option(\"display.max_colwidth\") # reset width of showing cols\n",
    "        \n",
    "        # deleting dataframe to free memory\n",
    "        if flag == \"complete\":\n",
    "            del [[df_resume, df_desc]]\n",
    "            gc.collect()\n",
    "            df_resume, df_desc = (pd.DataFrame() for i in range(2))\n",
    "        else:\n",
    "            del df_resume\n",
    "            gc.collect()\n",
    "            df_resume = pd.DataFrame()\n",
    "            \n",
    "               \n",
    "def plot_values_missingno(df, first_col, last_col, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Plotting missing values with missingno\n",
    "\n",
    "    Parameters\n",
    "    -----------------\n",
    "        df (pandas.DataFrame): Dataset to analyze.\n",
    "        first_col (int): First column to graph.\n",
    "        last_col (int): Last column to graph.\n",
    "        numbers_plot (int): Total numbers of graphs.\n",
    "        plot_number (int): Number of the graph.\n",
    "        \n",
    "    Returns:\n",
    "    -----------------\n",
    "        None. \n",
    "        Plotting the missing values with missingno\n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting the variables\n",
    "    numbers_plot = kwargs.get(\"numbers_plot\", None)\n",
    "    plot_number = kwargs.get(\"plot_number\", None)\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(2,1)\n",
    "    msno.matrix(df.iloc[:, first_col:last_col], sparkline=False, fontsize=14, ax=axs[0])\n",
    "    msno.bar(df.iloc[:, first_col:last_col], ax=axs[1], fontsize=14)            \n",
    "\n",
    "    for ax in axs:\n",
    "        labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "        short_labels = [s[:8] + \"...\" + s[-8:] if len(s) > 16 else s for s in labels]\n",
    "        ax.axes.set_xticklabels(short_labels)\n",
    "\n",
    "    fig.set_size_inches(18,14)\n",
    "    [ax.grid() for ax in axs.flatten()];\n",
    "    [sns.despine(ax=ax, right=False, left=False, top=False, bottom=False) for ax in axs.flatten()];\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.92])\n",
    "    \n",
    "    if plot_number == None:\n",
    "        fig.suptitle(\"Missing data overview\", fontweight=\"bold\", fontsize=20)\n",
    "    else:\n",
    "        fig.suptitle(\"Missing data overview\\n(part \" + str(plot_number) + \"/\" + str(numbers_plot) + \")\", fontweight=\"bold\", fontsize=20)       \n",
    "\n",
    "    plt.show()\n",
    "                        \n",
    "            \n",
    "def plot_missing_values(df, numbers_col):\n",
    "    \"\"\"\n",
    "    Method used for plotting missing values\n",
    "\n",
    "    Parameters\n",
    "    -----------------\n",
    "        df (pandas.DataFrame): Dataset to analyze.\n",
    "        numbers_col (int): Number of columns to show in each image.\n",
    "        \n",
    "    Returns:\n",
    "    -----------------\n",
    "        None. \n",
    "    \"\"\"\n",
    "    \n",
    "    first_col = 0\n",
    "    \n",
    "    if df.shape[1] // numbers_col != 0:\n",
    "        \n",
    "        for i in range (1, df.shape[1] // numbers_col + 1):\n",
    "            \n",
    "            if i == df.shape[1] // numbers_col:\n",
    "                last_col = None\n",
    "            else:\n",
    "                last_col = i * numbers_col\n",
    "\n",
    "            plot_values_missingno(df, first_col, last_col, numbers_plot=(df.shape[1] // numbers_col), plot_number=i)\n",
    "\n",
    "            if i == data.shape[1] // 30:\n",
    "                # deleting dataframe to free memory\n",
    "                del [df]\n",
    "                gc.collect()\n",
    "                df = pd.DataFrame()\n",
    "\n",
    "                break            \n",
    "            else:\n",
    "                first_col = last_col + 1\n",
    "    else:\n",
    "        \n",
    "        plot_values_missingno(df, first_col, None)\n",
    "            \n",
    "        del [df]\n",
    "        gc.collect()\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "\n",
    "def encode(df):\n",
    "    \"\"\"\n",
    "    Function to encode non-null data and replace it in the original data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------------\n",
    "        df (pandas.DataFrame): Dataset to analyze\n",
    "\n",
    "    Returns:\n",
    "    -----------------\n",
    "        df (pandas.DataFrame): DataFrame comparison.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Instante package to use\n",
    "    encoder = OrdinalEncoder()\n",
    "\n",
    "    # Retains only non-null values\n",
    "    no_nulls = np.array(df.dropna())\n",
    "    \n",
    "    # Reshapes the df for encoding\n",
    "    impute_reshape = no_nulls.reshape(-1,1)\n",
    "    \n",
    "    # Encode df\n",
    "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "    \n",
    "    # Assign back encoded values to non-null values\n",
    "    df.loc[df.notnull()] = np.squeeze(impute_ordinal)\n",
    "    \n",
    "    return df\n",
    "        \n",
    "\n",
    "class GroupImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" \n",
    "    Class used for imputing missing values in a pd.DataFrame using either mean or median of a group.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------------  \n",
    "        group_cols (list) : List of columns used for calculating the aggregated value \n",
    "        strategy (str) : The strategy to be used for remplacement, can be one of [\"mean\", \"median\", \"mode\"]\n",
    "        \n",
    "    Returns:\n",
    "    -----------------\n",
    "        X (array-like) : The array with imputed values in the target column\n",
    "   \"\"\"    \n",
    "    \n",
    "    def __init__(self, group_cols, target, strategy=\"mean\"):\n",
    "        \n",
    "        assert strategy in [\"mean\", \"median\"], \"Unrecognized value for metric, should be mean/median\"\n",
    "        assert type(group_cols) == list, \"group_cols should be a list of columns\"\n",
    "        assert type(target) == list, \"target should be a string\"\n",
    "        \n",
    "        self.group_cols = group_cols\n",
    "        self.target = target\n",
    "        self.strategy = strategy\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        assert pd.isnull(X[self.group_cols]).any(axis=None) == False, \"There are missing values in group_cols\"\n",
    "        \n",
    "        impute_map = X.groupby(self.group_cols)[self.target].agg(self.strategy) \\\n",
    "                                                            .reset_index(drop=False)\n",
    "        \n",
    "        self.impute_map_ = impute_map\n",
    "        \n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # make sure that the imputer was fitted\n",
    "        check_is_fitted(self, \"impute_map_\")\n",
    "        \n",
    "        X = X.copy()\n",
    "        \n",
    "        for index, row in self.impute_map_.iterrows():\n",
    "            ind = (X[self.group_cols] == row[self.group_cols]).all(axis=1)\n",
    "            X.loc[ind, self.target] = X.loc[ind, self.target].fillna(row[self.target])\n",
    "        \n",
    "        return X.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
